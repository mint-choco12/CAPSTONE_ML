{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbc4c873-4ca3-4b1d-9940-af660fa90572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24bb0394-1130-4cf3-be72-8368e03d1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produk Desc\n",
      "(2000, 10)\n",
      "[[0 0 0 0 1 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 1 0]]\n",
      "Produk classes: ['Booster' 'Calming Mask' 'Cleanser' 'Essence' 'Mask' 'Moisturizer'\n",
      " 'Serum' 'Spot Treatment' 'Sunscreen' 'Toner']\n",
      "Fitur Desc\n",
      "(2000, 15)\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]]\n",
      "Bahan Desc\n",
      "(2000, 12)\n",
      "[[1 0 0 0 0 0 0 1 1 0 0 1]\n",
      " [1 0 0 0 1 0 0 0 1 0 0 1]]\n",
      "Bahan yang terpisah: ['Allantoin' 'Aloe Vera' 'Bakuchiol' 'Ceramide' 'Cica' 'Glycerin' 'Glycol'\n",
      " 'Niacinamide' 'Panthenol' 'Retinol' 'Salicylic Acid' 'Water']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('file_updated.csv')\n",
    "\n",
    "# Mengonversi kolom 'Jawaban' dari string menjadi list\n",
    "data['Jawaban'] = data['Jawaban'].apply(lambda x: eval(x))  # Mengubah string list menjadi list Python\n",
    "\n",
    "# Preprocessing Produk\n",
    "#label_encoder_produk = LabelEncoder()\n",
    "# Initialize MultiLabelBinarizer for Produk\n",
    "label_encoder_produk = MultiLabelBinarizer()\n",
    "\n",
    "# Split the 'Produk' column by commas to create a list of products\n",
    "data['Produk'] = data['Produk'].apply(lambda x: x.split(', '))\n",
    "\n",
    "# Apply MultiLabelBinarizer to encode the 'Produk' column\n",
    "produk_encoded = label_encoder_produk.fit_transform(data['Produk'])\n",
    "\n",
    "print(\"Produk Desc\")\n",
    "print(produk_encoded.shape)  # Shape of the encoded matrix\n",
    "print(produk_encoded[:2])  # Displaying first two rows of the encoded data\n",
    "\n",
    "# Checking the labels used for encoding\n",
    "print(\"Produk classes:\", label_encoder_produk.classes_)\n",
    "\n",
    "\n",
    "# Preprocessing Fitur\n",
    "#label_encoder_fitur = LabelEncoder()\n",
    "label_encoder_fitur = MultiLabelBinarizer()\n",
    "#data['Fitur'] = label_encoder_fitur.fit_transform(data['Fitur'])\n",
    "data['Fitur'] = data['Fitur'].apply(lambda x: x.split(', '))\n",
    "fitur_encoded = label_encoder_fitur.fit_transform(data['Fitur'])\n",
    "\n",
    "print(\"Fitur Desc\")\n",
    "#print(data['Fitur'].shape)\n",
    "#print(data['Fitur'][:2])\n",
    "print(fitur_encoded.shape)\n",
    "print(fitur_encoded[:2])\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing Bahan\n",
    "bahan_binarizer = MultiLabelBinarizer()\n",
    "data['Bahan'] = data['Bahan'].apply(lambda x: x.split(', '))  # Pastikan bahan berbentuk list\n",
    "bahan_encoded = bahan_binarizer.fit_transform(data['Bahan'])\n",
    "\n",
    "print(\"Bahan Desc\")\n",
    "\n",
    "print(bahan_encoded.shape)\n",
    "print(bahan_encoded[:2])\n",
    "print(\"Bahan yang terpisah:\", bahan_binarizer.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c95f44b6-1f25-4d40-b792-21aefdf150b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah kolom 'Jawaban' menjadi array numpy\n",
    "X = np.array(data['Jawaban'].tolist())  # Mengubah list ke dalam array\n",
    "\n",
    "# Output Labels\n",
    "y_produk = produk_encoded\n",
    "y_fitur = fitur_encoded\n",
    "y_bahan = bahan_encoded\n",
    "\n",
    "# Normalize Input\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_produk_train, y_produk_test, y_fitur_train, y_fitur_test, y_bahan_train, y_bahan_test = train_test_split(\n",
    "    X, y_produk, y_fitur, y_bahan, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c952ca60-8cf8-4d48-be53-1a0133988a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produk shape: (1600, 10)\n",
      "Fitur shape: (1600, 15)\n",
      "Bahan shape: (1600, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Produk shape:', y_produk_train.shape)\n",
    "print('Fitur shape:', y_fitur_train.shape)\n",
    "print('Bahan shape:', y_bahan_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "862393d3-510c-440e-9b48-b0c99a46ad88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - Bahan_Output_accuracy: 0.0977 - Bahan_Output_loss: 5.6295 - Fitur_Output_accuracy: 0.1144 - Fitur_Output_loss: 6.4093 - Produk_Output_accuracy: 0.0824 - Produk_Output_loss: 0.8608 - loss: 13.8055 - val_Bahan_Output_accuracy: 0.0688 - val_Bahan_Output_loss: 4.3399 - val_Fitur_Output_accuracy: 0.1688 - val_Fitur_Output_loss: 5.3129 - val_Produk_Output_accuracy: 0.0500 - val_Produk_Output_loss: 0.6575 - val_loss: 11.2068\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Bahan_Output_accuracy: 0.1502 - Bahan_Output_loss: 4.7584 - Fitur_Output_accuracy: 0.2739 - Fitur_Output_loss: 5.4809 - Produk_Output_accuracy: 0.0937 - Produk_Output_loss: 0.7641 - loss: 11.8985 - val_Bahan_Output_accuracy: 0.0437 - val_Bahan_Output_loss: 4.1006 - val_Fitur_Output_accuracy: 0.2375 - val_Fitur_Output_loss: 5.2947 - val_Produk_Output_accuracy: 0.1063 - val_Produk_Output_loss: 0.6388 - val_loss: 10.9260\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.1372 - Bahan_Output_loss: 4.4994 - Fitur_Output_accuracy: 0.2956 - Fitur_Output_loss: 5.3931 - Produk_Output_accuracy: 0.1158 - Produk_Output_loss: 0.7118 - loss: 11.4955 - val_Bahan_Output_accuracy: 0.0312 - val_Bahan_Output_loss: 3.9318 - val_Fitur_Output_accuracy: 0.2000 - val_Fitur_Output_loss: 5.2766 - val_Produk_Output_accuracy: 0.1125 - val_Produk_Output_loss: 0.5977 - val_loss: 10.6952\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.1290 - Bahan_Output_loss: 4.2389 - Fitur_Output_accuracy: 0.3157 - Fitur_Output_loss: 5.2736 - Produk_Output_accuracy: 0.1066 - Produk_Output_loss: 0.6410 - loss: 11.0423 - val_Bahan_Output_accuracy: 0.0312 - val_Bahan_Output_loss: 3.7707 - val_Fitur_Output_accuracy: 0.1625 - val_Fitur_Output_loss: 5.3193 - val_Produk_Output_accuracy: 0.0938 - val_Produk_Output_loss: 0.5426 - val_loss: 10.5202\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.1178 - Bahan_Output_loss: 3.8928 - Fitur_Output_accuracy: 0.3249 - Fitur_Output_loss: 5.2344 - Produk_Output_accuracy: 0.1083 - Produk_Output_loss: 0.5452 - loss: 10.5595 - val_Bahan_Output_accuracy: 0.0250 - val_Bahan_Output_loss: 3.7067 - val_Fitur_Output_accuracy: 0.1813 - val_Fitur_Output_loss: 5.4638 - val_Produk_Output_accuracy: 0.0562 - val_Produk_Output_loss: 0.4856 - val_loss: 10.5422\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0998 - Bahan_Output_loss: 3.7853 - Fitur_Output_accuracy: 0.3496 - Fitur_Output_loss: 5.3436 - Produk_Output_accuracy: 0.0806 - Produk_Output_loss: 0.4680 - loss: 10.4830 - val_Bahan_Output_accuracy: 0.0188 - val_Bahan_Output_loss: 3.7450 - val_Fitur_Output_accuracy: 0.1875 - val_Fitur_Output_loss: 5.5939 - val_Produk_Output_accuracy: 0.0250 - val_Produk_Output_loss: 0.4345 - val_loss: 10.6591\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0863 - Bahan_Output_loss: 3.7137 - Fitur_Output_accuracy: 0.3716 - Fitur_Output_loss: 5.2060 - Produk_Output_accuracy: 0.0667 - Produk_Output_loss: 0.3972 - loss: 10.2026 - val_Bahan_Output_accuracy: 0.0125 - val_Bahan_Output_loss: 3.9061 - val_Fitur_Output_accuracy: 0.1688 - val_Fitur_Output_loss: 5.8030 - val_Produk_Output_accuracy: 0.0250 - val_Produk_Output_loss: 0.4081 - val_loss: 11.0029\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0714 - Bahan_Output_loss: 3.8398 - Fitur_Output_accuracy: 0.3819 - Fitur_Output_loss: 5.3964 - Produk_Output_accuracy: 0.0534 - Produk_Output_loss: 0.3652 - loss: 10.4871 - val_Bahan_Output_accuracy: 0.0125 - val_Bahan_Output_loss: 4.2602 - val_Fitur_Output_accuracy: 0.1875 - val_Fitur_Output_loss: 5.8945 - val_Produk_Output_accuracy: 0.0125 - val_Produk_Output_loss: 0.3979 - val_loss: 11.4388\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0676 - Bahan_Output_loss: 4.1948 - Fitur_Output_accuracy: 0.3685 - Fitur_Output_loss: 5.3054 - Produk_Output_accuracy: 0.0617 - Produk_Output_loss: 0.3474 - loss: 10.7341 - val_Bahan_Output_accuracy: 0.0125 - val_Bahan_Output_loss: 4.4567 - val_Fitur_Output_accuracy: 0.2188 - val_Fitur_Output_loss: 5.8051 - val_Produk_Output_accuracy: 0.0125 - val_Produk_Output_loss: 0.3825 - val_loss: 11.5321\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0706 - Bahan_Output_loss: 4.5936 - Fitur_Output_accuracy: 0.3426 - Fitur_Output_loss: 5.5603 - Produk_Output_accuracy: 0.0481 - Produk_Output_loss: 0.3379 - loss: 11.3803 - val_Bahan_Output_accuracy: 0.0125 - val_Bahan_Output_loss: 5.0225 - val_Fitur_Output_accuracy: 0.2438 - val_Fitur_Output_loss: 5.8828 - val_Produk_Output_accuracy: 0.0125 - val_Produk_Output_loss: 0.3726 - val_loss: 12.1690\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0689 - Bahan_Output_loss: 5.1448 - Fitur_Output_accuracy: 0.3487 - Fitur_Output_loss: 5.8642 - Produk_Output_accuracy: 0.0447 - Produk_Output_loss: 0.3273 - loss: 12.2285 - val_Bahan_Output_accuracy: 0.0188 - val_Bahan_Output_loss: 5.5328 - val_Fitur_Output_accuracy: 0.3125 - val_Fitur_Output_loss: 5.7591 - val_Produk_Output_accuracy: 0.0125 - val_Produk_Output_loss: 0.3552 - val_loss: 12.5428\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0610 - Bahan_Output_loss: 5.7839 - Fitur_Output_accuracy: 0.3293 - Fitur_Output_loss: 5.9937 - Produk_Output_accuracy: 0.0334 - Produk_Output_loss: 0.3334 - loss: 13.0080 - val_Bahan_Output_accuracy: 0.0250 - val_Bahan_Output_loss: 6.4324 - val_Fitur_Output_accuracy: 0.3000 - val_Fitur_Output_loss: 5.9498 - val_Produk_Output_accuracy: 0.0125 - val_Produk_Output_loss: 0.3466 - val_loss: 13.6300\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Bahan_Output_accuracy: 0.0633 - Bahan_Output_loss: 6.2360 - Fitur_Output_accuracy: 0.3440 - Fitur_Output_loss: 6.1127 - Produk_Output_accuracy: 0.0359 - Produk_Output_loss: 0.3266 - loss: 13.5782 - val_Bahan_Output_accuracy: 0.0437 - val_Bahan_Output_loss: 7.3230 - val_Fitur_Output_accuracy: 0.2937 - val_Fitur_Output_loss: 6.1633 - val_Produk_Output_accuracy: 0.0312 - val_Produk_Output_loss: 0.3275 - val_loss: 14.7223\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Bahan_Output_accuracy: 0.0525 - Bahan_Output_loss: 7.1686 - Fitur_Output_accuracy: 0.3792 - Fitur_Output_loss: 6.5629 - Produk_Output_accuracy: 0.0479 - Produk_Output_loss: 0.3281 - loss: 14.9704 - val_Bahan_Output_accuracy: 0.0562 - val_Bahan_Output_loss: 9.0431 - val_Fitur_Output_accuracy: 0.3313 - val_Fitur_Output_loss: 6.8468 - val_Produk_Output_accuracy: 0.0375 - val_Produk_Output_loss: 0.3202 - val_loss: 17.1280\n",
      "Total Loss: 10.64\n",
      "Produk Loss: 0.55, Accuracy: 0.03\n",
      "Fitur Loss: 5.31, Accuracy: 0.20\n",
      "Bahan Loss: 3.89, Accuracy: 0.18\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 135\u001b[0m\n\u001b[0;32m    133\u001b[0m produk_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_normalized)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get Produk predictions\u001b[39;00m\n\u001b[0;32m    134\u001b[0m predicted_produk_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(produk_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m predicted_produk \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder_produk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_produk_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Decode Fitur predictions (multi-label classification)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m fitur_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_normalized)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:925\u001b[0m, in \u001b[0;36mMultiLabelBinarizer.inverse_transform\u001b[1;34m(self, yt)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the given indicator matrix into label sets.\u001b[39;00m\n\u001b[0;32m    911\u001b[0m \n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m    `classes_[j]` for each `yt[i, j] == 1`.\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    923\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43myt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_):\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    927\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected indicator for \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m classes, but got \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    928\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_), yt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    929\u001b[0m         )\n\u001b[0;32m    930\u001b[0m     )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(yt):\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Define ANN model\n",
    "input_layer = Input(shape=(14,))\n",
    "# hidden_layer1 = Dense(2048, activation='relu')(input_layer)\n",
    "# dropout1 = Dropout(0.3)(hidden_layer1)  # Dropout layer for regularization\n",
    "# hidden_layer2 = Dense(1024, activation='relu')(dropout1)\n",
    "# dropout2 = Dropout(0.5)(hidden_layer2)\n",
    "# hidden_layer3 = Dense(512, activation='relu')(dropout2)\n",
    "\n",
    "# # Output layer for Produk (jumlah kelas produk harus sesuai dengan target)\n",
    "# output_produk = Dense(12, activation='softmax', name='Produk_Output')(hidden_layer3)\n",
    "\n",
    "# # Output layer for Fitur (jumlah kelas fitur harus sesuai dengan target)\n",
    "# output_fitur = Dense(15, activation='softmax', name='Fitur_Output')(hidden_layer3)\n",
    "\n",
    "# # Output layer for Bahan (jumlah bahan yang terpisah, yang berupa binari, sesuai dengan target)\n",
    "# output_bahan = Dense(10, activation='sigmoid', name='Bahan_Output')(hidden_layer3)\n",
    "\n",
    "# Add hidden layers with BatchNormalization and L2 regularization\n",
    "hidden_layer1 = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(input_layer)\n",
    "batch_norm1 = BatchNormalization()(hidden_layer1)\n",
    "dropout1 = Dropout(0.5)(batch_norm1)\n",
    "\n",
    "hidden_layer2 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(dropout1)\n",
    "batch_norm2 = BatchNormalization()(hidden_layer2)\n",
    "dropout2 = Dropout(0.5)(batch_norm2)\n",
    "\n",
    "hidden_layer3 = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(dropout2)\n",
    "batch_norm3 = BatchNormalization()(hidden_layer3)\n",
    "\n",
    "# Output layer for Produk\n",
    "output_produk = Dense(12, activation='softmax', name='Produk_Output')(batch_norm3)\n",
    "\n",
    "# Output layer for Fitur\n",
    "output_fitur = Dense(15, activation='softmax', name='Fitur_Output')(batch_norm3)\n",
    "\n",
    "# Output layer for Bahan\n",
    "output_bahan = Dense(10, activation='sigmoid', name='Bahan_Output')(batch_norm3)\n",
    "\n",
    "\n",
    "\n",
    "# Combine model\n",
    "model = Model(inputs=input_layer, outputs=[output_produk, output_fitur, output_bahan])\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.0007)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'Produk_Output': 'categorical_crossentropy',\n",
    "                    'Fitur_Output': 'categorical_crossentropy',\n",
    "                    'Bahan_Output': 'binary_crossentropy'},\n",
    "              metrics={'Produk_Output': 'accuracy',\n",
    "                       'Fitur_Output': 'accuracy',\n",
    "                       'Bahan_Output': 'accuracy'})\n",
    "\n",
    "\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     {'Produk_Output': y_produk_train, 'Fitur_Output': y_fitur_train, 'Bahan_Output': y_bahan_train},\n",
    "#     epochs=50,\n",
    "#     batch_size=16,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1\n",
    "# )\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     {'Produk_Output': y_produk_train, 'Fitur_Output': y_fitur_train, 'Bahan_Output': y_bahan_train},\n",
    "#     epochs=100,\n",
    "#     batch_size=16,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1\n",
    "# )\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'Produk_Output': y_produk_train, 'Fitur_Output': y_fitur_train, 'Bahan_Output': y_bahan_train},\n",
    "    epochs=50,\n",
    "    batch_size=32,  # Increased batch size for better generalization\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "# loss, produk_acc, fitur_acc, bahan_acc = model.evaluate(\n",
    "#     X_test,\n",
    "#     {'Produk_Output': y_produk_test, 'Fitur_Output': y_fitur_test, 'Bahan_Output': y_bahan_test},\n",
    "#     verbose=0\n",
    "# )\n",
    "\n",
    "# print(f\"Produk Accuracy: {produk_acc:.2f}\")\n",
    "# print(f\"Fitur Accuracy: {fitur_acc:.2f}\")\n",
    "# print(f\"Bahan Accuracy: {bahan_acc:.2f}\")\n",
    "\n",
    "# Evaluate model\n",
    "results = model.evaluate(\n",
    "    X_test,\n",
    "    {'Produk_Output': y_produk_test, 'Fitur_Output': y_fitur_test, 'Bahan_Output': y_bahan_test},\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Unpack the results and print\n",
    "total_loss = results[0]\n",
    "produk_loss = results[1]\n",
    "fitur_loss = results[2]\n",
    "bahan_loss = results[3]\n",
    "produk_acc = results[4]\n",
    "fitur_acc = results[5]\n",
    "bahan_acc = results[6]\n",
    "\n",
    "print(f\"Total Loss: {total_loss:.2f}\")\n",
    "print(f\"Produk Loss: {produk_loss:.2f}, Accuracy: {produk_acc:.2f}\")\n",
    "print(f\"Fitur Loss: {fitur_loss:.2f}, Accuracy: {fitur_acc:.2f}\")\n",
    "print(f\"Bahan Loss: {bahan_loss:.2f}, Accuracy: {bahan_acc:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Normalize X_test using the same scaler as training\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# # Predict for X_test\n",
    "# produk_pred, fitur_pred, bahan_pred = model.predict(X_test_normalized)\n",
    "\n",
    "\n",
    "# Decode Produk predictions (single-label classification)\n",
    "produk_pred = model.predict(X_test_normalized)[0]  # Get Produk predictions\n",
    "predicted_produk_indices = np.argmax(produk_pred, axis=1)\n",
    "predicted_produk = label_encoder_produk.inverse_transform(predicted_produk_indices)\n",
    "\n",
    "# Decode Fitur predictions (multi-label classification)\n",
    "fitur_pred = model.predict(X_test_normalized)[1]\n",
    "predicted_fitur = label_encoder_fitur.inverse_transform((fitur_pred > 0.5).astype(int))\n",
    "\n",
    "# Decode Bahan predictions (multi-label classification)\n",
    "bahan_pred = model.predict(X_test_normalized)[2]\n",
    "predicted_bahan = bahan_binarizer.inverse_transform((bahan_pred > 0.5).astype(int))\n",
    "\n",
    "# Display predictions for the first few samples\n",
    "for i in range(5):  # Displaying results for the first 5 test samples\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(f\"Rekomendasi Produk: {predicted_produk[i]}\")\n",
    "    print(f\"Rekomendasi Fitur: {', '.join(predicted_fitur[i])}\")\n",
    "    print(f\"Rekomendasi Bahan: {', '.join(predicted_bahan[i])}\")\n",
    "    print(\"-\" * 30)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
